import os
import yaml
from dotenv import load_dotenv
import streamlit as st
from openai import OpenAI

# --------------------
# åˆæœŸè¨­å®š
# --------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", None)  # Azure/äº’æ›APIç”¨ã«ä»»æ„
MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

if not OPENAI_API_KEY:
    st.stop()

client = (
    OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    if OPENAI_BASE_URL
    else OpenAI()
)

st.set_page_config(
    page_title="ã‚‚ã—ã‚‚AI",
    page_icon="ğŸ­",
    layout="centered",
)

# --------------------
# ãƒ˜ãƒƒãƒ€ãƒ¼
# --------------------
st.markdown(
    """
    <div style="text-align:center; padding: 16px; border-radius: 16px; background: linear-gradient(135deg,#EEF2FF,#ECFEFF);">
      <h1 style="margin:0;">ã‚‚ã—ã‚‚AI ğŸ­</h1>
      <p style="margin:6px 0 0;">ã‚‚ã—ã‚‚â—¯â—¯ãŒè©±ã›ãŸã‚‰ï¼Ÿã‚’ã€LLMã§ã‚«ã‚¿ãƒã«ã€‚</p>
    </div>
    """,
    unsafe_allow_html=True,
)

# --------------------
# ã‚­ãƒ£ãƒ©èª­ã¿è¾¼ã¿
# --------------------
with open("characters.yaml", "r", encoding="utf-8") as f:
    CHARACTERS = yaml.safe_load(f)

name_to_char = {c["name"]: c for c in CHARACTERS}

# --------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# --------------------
with st.sidebar:
    st.header("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼")
    selected_name = st.selectbox("ç›¸æ‰‹ã‚’é¸ã¶", [c["name"] for c in CHARACTERS])
    sel = name_to_char[selected_name]

    st.divider()
    st.caption("å‡ºåŠ›ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆçŸ­ã‚æ¨å¥¨ï¼‰")
    max_tokens = st.slider(
        "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³", min_value=256, max_value=2048, value=512, step=64
    )
    temperature = st.slider("å‰µé€ æ€§ (temperature)", 0.0, 1.5, 0.7, 0.1)

    st.divider()
    if st.button("ä¼šè©±ãƒªã‚»ãƒƒãƒˆ", type="primary"):
        st.session_state.messages = []
        st.experimental_rerun()

# --------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
# --------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

# --------------------
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚­ãƒ£ãƒ©äººæ ¼ï¼‰
# --------------------
SYSTEM_PROMPT = f"""
ã‚ãªãŸã¯ã€{sel['name']}ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚
ä»¥ä¸‹ã®ã‚­ãƒ£ãƒ©è¨­å®šã‚’å¿…ãšå®ˆã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨è‡ªç„¶ã«å¯¾è©±ã—ã¦ãã ã•ã„ã€‚

[ã‚­ãƒ£ãƒ©è¨­å®š]
{sel['style']}

[å‡ºåŠ›æŒ‡é‡]
- 1~3æ®µè½ã§ç°¡æ½”ã«ã€‚å¿…è¦ã«å¿œã˜ã¦ç®‡æ¡æ›¸ãã€‚
- ä½™è¨ˆãªå‰ç½®ãã‚„è‡ªå·±è¨€åŠã¯é¿ã‘ã‚‹ã€‚
- é›£ã—ã„è©±é¡Œã¯æ¯”å–©ã‚„ä¾‹ã‚’1ã¤æ·»ãˆã¦ã‚ã‹ã‚Šã‚„ã™ãã€‚
"""

# --------------------
# æ—¢å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æç”»
# --------------------
avatar = sel.get("avatar")
for m in st.session_state.messages:
    with st.chat_message(
        m["role"], avatar=(avatar if m["role"] == "assistant" else None)
    ):
        st.markdown(m["content"])

# --------------------
# å…¥åŠ›ã‚¨ãƒªã‚¢
# --------------------
if prompt := st.chat_input("è©±ã—ã‹ã‘ã¦ã¿ã‚ˆã†â€¦"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # è¿”ç­”ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
    with st.chat_message("assistant", avatar=avatar):
        stream = client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "system", "content": SYSTEM_PROMPT}]
            + st.session_state.messages,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True,
        )
        full = ""
        placeholder = st.empty()
        for chunk in stream:
            delta = chunk.choices[0].delta.content or ""
            if delta:
                full += delta
                placeholder.markdown(full)
        st.session_state.messages.append({"role": "assistant", "content": full})
